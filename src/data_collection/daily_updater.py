import schedule
import time
import pandas as pd
from datetime import datetime, timedelta
import requests
import logging
from google.colab import files

class DailyUpdater:
    def __init__(self, api_key):
        self.api_key = api_key
        self.setup_logging()
        
    def setup_logging(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„"""
        logging.basicConfig(
            filename='data_update.log',
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
    
    def update_gold_prices(self):
        """ØªØ­Ø¯ÙŠØ« Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨ Ø§Ù„ÙŠÙˆÙ…ÙŠØ©"""
        try:
            url = f"https://api.twelvedata.com/time_series?symbol=XAU/USD&interval=1day&outputsize=2&apikey={self.api_key}"
            response = requests.get(url)
            data = response.json()
            
            if "values" in data:
                new_data = pd.DataFrame(data["values"])
                new_data = new_data.iloc[::-1]
                
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
                historical_data = pd.read_csv('../data/raw/gold/gold_historical_7148_days.csv')
                
                # Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
                updated_data = pd.concat([historical_data, new_data], ignore_index=True)
                updated_data = updated_data.drop_duplicates('datetime')
                
                # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
                updated_data.to_csv('../data/raw/gold/gold_historical_updated.csv', index=False)
                
                logging.info(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨: {len(new_data)} ÙŠÙˆÙ… Ø¬Ø¯ÙŠØ¯")
                return True
                
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø°Ù‡Ø¨: {str(e)}")
            return False
    
    def update_news(self):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ÙŠÙˆÙ…ÙŠØ©"""
        try:
            # ÙƒÙˆØ¯ Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°ÙŠ Ù„Ø¯ÙŠÙƒ
            news_df = self.collect_daily_news()
            news_df.to_csv('../data/raw/news/daily_news.csv', mode='a', header=False)
            
            logging.info(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {len(news_df)} Ø®Ø¨Ø± Ø¬Ø¯ÙŠØ¯")
            return True
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {str(e)}")
            return False
    
    def run_daily_updates(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ©"""
        logging.info("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ©")
        
        # Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ø§Ù…
        schedule.every().day.at("08:00").do(self.update_gold_prices)
        schedule.every().hour().do(self.update_news)
        
        while True:
            schedule.run_pending()
            time.sleep(60)

# âœ… Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙÙˆØ±ÙŠ
if __name__ == "__main__":
    updater = DailyUpdater("9fe19365755a4339ae1e7a1392fcd8e6")
    
    # ØªØ­Ø¯ÙŠØ« ÙÙˆØ±ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    updater.update_gold_prices()
    updater.update_news()
    
    print("âœ… ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø¨Ù†Ø¬Ø§Ø­!")
